{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./road_tracks/aalborg/24.csv\n",
      "./road_tracks/aalborg/19.csv\n",
      "./road_tracks/aalborg/11.csv\n",
      "./road_tracks/aalborg/4.csv\n",
      "./road_tracks/aalborg/26.csv\n",
      "./road_tracks/aalborg/9.csv\n",
      "./road_tracks/aalborg/10.csv\n",
      "./road_tracks/aalborg/16.csv\n",
      "./road_tracks/aalborg/8.csv\n",
      "./road_tracks/aalborg/5.csv\n",
      "./road_tracks/aalborg/21.csv\n",
      "./road_tracks/aalborg/3.csv\n",
      "./road_tracks/aalborg/25.csv\n",
      "./road_tracks/aalborg/23.csv\n",
      "./road_tracks/aalborg/20.csv\n",
      "./road_tracks/aalborg/13.csv\n",
      "./road_tracks/aalborg/28.csv\n",
      "./road_tracks/aalborg/30.csv\n",
      "./road_tracks/aalborg/1.csv\n",
      "./road_tracks/aalborg/18.csv\n",
      "./road_tracks/aalborg/6.csv\n",
      "./road_tracks/aalborg/7.csv\n",
      "./road_tracks/aalborg/22.csv\n",
      "./road_tracks/aalborg/15.csv\n",
      "./road_tracks/aalborg/2.csv\n",
      "./road_tracks/aalborg/17.csv\n",
      "./road_tracks/aalborg/14.csv\n",
      "./road_tracks/aalborg/27.csv\n",
      "./road_tracks/aalborg/12.csv\n",
      "./road_tracks/aalborg/29.csv\n",
      "./road_tracks/alpine-1/24.csv\n",
      "./road_tracks/alpine-1/19.csv\n",
      "./road_tracks/alpine-1/11.csv\n",
      "./road_tracks/alpine-1/4.csv\n",
      "./road_tracks/alpine-1/26.csv\n",
      "./road_tracks/alpine-1/9.csv\n",
      "./road_tracks/alpine-1/10.csv\n",
      "./road_tracks/alpine-1/16.csv\n",
      "./road_tracks/alpine-1/8.csv\n",
      "./road_tracks/alpine-1/5.csv\n",
      "./road_tracks/alpine-1/21.csv\n",
      "./road_tracks/alpine-1/3.csv\n",
      "./road_tracks/alpine-1/25.csv\n",
      "./road_tracks/alpine-1/23.csv\n",
      "./road_tracks/alpine-1/20.csv\n",
      "./road_tracks/alpine-1/13.csv\n",
      "./road_tracks/alpine-1/28.csv\n",
      "./road_tracks/alpine-1/30.csv\n",
      "./road_tracks/alpine-1/1.csv\n",
      "./road_tracks/alpine-1/18.csv\n",
      "./road_tracks/alpine-1/6.csv\n",
      "./road_tracks/alpine-1/7.csv\n",
      "./road_tracks/alpine-1/22.csv\n",
      "./road_tracks/alpine-1/15.csv\n",
      "./road_tracks/alpine-1/2.csv\n",
      "./road_tracks/alpine-1/17.csv\n",
      "./road_tracks/alpine-1/14.csv\n",
      "./road_tracks/alpine-1/27.csv\n",
      "./road_tracks/alpine-1/12.csv\n",
      "./road_tracks/alpine-1/29.csv\n",
      "./road_tracks/alpine-2/24.csv\n",
      "./road_tracks/alpine-2/19.csv\n",
      "./road_tracks/alpine-2/11.csv\n",
      "./road_tracks/alpine-2/4.csv\n",
      "./road_tracks/alpine-2/26.csv\n",
      "./road_tracks/alpine-2/9.csv\n",
      "./road_tracks/alpine-2/10.csv\n",
      "./road_tracks/alpine-2/16.csv\n",
      "./road_tracks/alpine-2/8.csv\n",
      "./road_tracks/alpine-2/5.csv\n",
      "./road_tracks/alpine-2/21.csv\n",
      "./road_tracks/alpine-2/3.csv\n",
      "./road_tracks/alpine-2/25.csv\n",
      "./road_tracks/alpine-2/23.csv\n",
      "./road_tracks/alpine-2/20.csv\n",
      "./road_tracks/alpine-2/13.csv\n",
      "./road_tracks/alpine-2/28.csv\n",
      "./road_tracks/alpine-2/30.csv\n",
      "./road_tracks/alpine-2/1.csv\n",
      "./road_tracks/alpine-2/18.csv\n",
      "./road_tracks/alpine-2/6.csv\n",
      "./road_tracks/alpine-2/7.csv\n",
      "./road_tracks/alpine-2/22.csv\n",
      "./road_tracks/alpine-2/15.csv\n",
      "./road_tracks/alpine-2/2.csv\n",
      "./road_tracks/alpine-2/17.csv\n",
      "./road_tracks/alpine-2/14.csv\n",
      "./road_tracks/alpine-2/27.csv\n",
      "./road_tracks/alpine-2/12.csv\n",
      "./road_tracks/alpine-2/29.csv\n",
      "./road_tracks/brondehach/24.csv\n",
      "./road_tracks/brondehach/19.csv\n",
      "./road_tracks/brondehach/11.csv\n",
      "./road_tracks/brondehach/4.csv\n",
      "./road_tracks/brondehach/26.csv\n",
      "./road_tracks/brondehach/9.csv\n",
      "./road_tracks/brondehach/10.csv\n",
      "./road_tracks/brondehach/16.csv\n",
      "./road_tracks/brondehach/8.csv\n",
      "./road_tracks/brondehach/5.csv\n",
      "./road_tracks/brondehach/21.csv\n",
      "./road_tracks/brondehach/3.csv\n",
      "./road_tracks/brondehach/25.csv\n",
      "./road_tracks/brondehach/23.csv\n",
      "./road_tracks/brondehach/20.csv\n",
      "./road_tracks/brondehach/13.csv\n",
      "./road_tracks/brondehach/28.csv\n",
      "./road_tracks/brondehach/30.csv\n",
      "./road_tracks/brondehach/1.csv\n",
      "./road_tracks/brondehach/18.csv\n",
      "./road_tracks/brondehach/6.csv\n",
      "./road_tracks/brondehach/7.csv\n",
      "./road_tracks/brondehach/22.csv\n",
      "./road_tracks/brondehach/15.csv\n",
      "./road_tracks/brondehach/2.csv\n",
      "./road_tracks/brondehach/17.csv\n",
      "./road_tracks/brondehach/14.csv\n",
      "./road_tracks/brondehach/27.csv\n",
      "./road_tracks/brondehach/12.csv\n",
      "./road_tracks/brondehach/29.csv\n",
      "./road_tracks/corkscrew/24.csv\n",
      "./road_tracks/corkscrew/19.csv\n",
      "./road_tracks/corkscrew/11.csv\n",
      "./road_tracks/corkscrew/4.csv\n",
      "./road_tracks/corkscrew/26.csv\n",
      "./road_tracks/corkscrew/9.csv\n",
      "./road_tracks/corkscrew/10.csv\n",
      "./road_tracks/corkscrew/16.csv\n",
      "./road_tracks/corkscrew/8.csv\n",
      "./road_tracks/corkscrew/5.csv\n",
      "./road_tracks/corkscrew/21.csv\n",
      "./road_tracks/corkscrew/3.csv\n",
      "./road_tracks/corkscrew/25.csv\n",
      "./road_tracks/corkscrew/23.csv\n",
      "./road_tracks/corkscrew/20.csv\n",
      "./road_tracks/corkscrew/13.csv\n",
      "./road_tracks/corkscrew/28.csv\n",
      "./road_tracks/corkscrew/30.csv\n",
      "./road_tracks/corkscrew/1.csv\n",
      "./road_tracks/corkscrew/18.csv\n",
      "./road_tracks/corkscrew/6.csv\n",
      "./road_tracks/corkscrew/7.csv\n",
      "./road_tracks/corkscrew/22.csv\n",
      "./road_tracks/corkscrew/15.csv\n",
      "./road_tracks/corkscrew/2.csv\n",
      "./road_tracks/corkscrew/17.csv\n",
      "./road_tracks/corkscrew/14.csv\n",
      "./road_tracks/corkscrew/27.csv\n",
      "./road_tracks/corkscrew/12.csv\n",
      "./road_tracks/corkscrew/29.csv\n",
      "./road_tracks/eroad/24.csv\n",
      "./road_tracks/eroad/19.csv\n",
      "./road_tracks/eroad/11.csv\n",
      "./road_tracks/eroad/4.csv\n",
      "./road_tracks/eroad/26.csv\n",
      "./road_tracks/eroad/9.csv\n",
      "./road_tracks/eroad/10.csv\n",
      "./road_tracks/eroad/16.csv\n",
      "./road_tracks/eroad/8.csv\n",
      "./road_tracks/eroad/5.csv\n",
      "./road_tracks/eroad/21.csv\n",
      "./road_tracks/eroad/3.csv\n",
      "./road_tracks/eroad/25.csv\n",
      "./road_tracks/eroad/23.csv\n",
      "./road_tracks/eroad/20.csv\n",
      "./road_tracks/eroad/13.csv\n",
      "./road_tracks/eroad/28.csv\n",
      "./road_tracks/eroad/30.csv\n",
      "./road_tracks/eroad/1.csv\n",
      "./road_tracks/eroad/18.csv\n",
      "./road_tracks/eroad/6.csv\n",
      "./road_tracks/eroad/7.csv\n",
      "./road_tracks/eroad/22.csv\n",
      "./road_tracks/eroad/15.csv\n",
      "./road_tracks/eroad/2.csv\n",
      "./road_tracks/eroad/17.csv\n",
      "./road_tracks/eroad/14.csv\n",
      "./road_tracks/eroad/27.csv\n",
      "./road_tracks/eroad/12.csv\n",
      "./road_tracks/eroad/29.csv\n",
      "./road_tracks/e-track-3/24.csv\n",
      "./road_tracks/e-track-3/19.csv\n",
      "./road_tracks/e-track-3/11.csv\n",
      "./road_tracks/e-track-3/4.csv\n",
      "./road_tracks/e-track-3/26.csv\n",
      "./road_tracks/e-track-3/9.csv\n",
      "./road_tracks/e-track-3/10.csv\n",
      "./road_tracks/e-track-3/16.csv\n",
      "./road_tracks/e-track-3/8.csv\n",
      "./road_tracks/e-track-3/5.csv\n",
      "./road_tracks/e-track-3/21.csv\n",
      "./road_tracks/e-track-3/3.csv\n",
      "./road_tracks/e-track-3/25.csv\n",
      "./road_tracks/e-track-3/23.csv\n",
      "./road_tracks/e-track-3/20.csv\n",
      "./road_tracks/e-track-3/13.csv\n",
      "./road_tracks/e-track-3/28.csv\n",
      "./road_tracks/e-track-3/30.csv\n",
      "./road_tracks/e-track-3/1.csv\n",
      "./road_tracks/e-track-3/18.csv\n",
      "./road_tracks/e-track-3/6.csv\n",
      "./road_tracks/e-track-3/7.csv\n",
      "./road_tracks/e-track-3/22.csv\n",
      "./road_tracks/e-track-3/15.csv\n",
      "./road_tracks/e-track-3/2.csv\n",
      "./road_tracks/e-track-3/17.csv\n",
      "./road_tracks/e-track-3/14.csv\n",
      "./road_tracks/e-track-3/27.csv\n",
      "./road_tracks/e-track-3/12.csv\n",
      "./road_tracks/e-track-3/29.csv\n",
      "./road_tracks/e-track-4/24.csv\n",
      "./road_tracks/e-track-4/19.csv\n",
      "./road_tracks/e-track-4/11.csv\n",
      "./road_tracks/e-track-4/4.csv\n",
      "./road_tracks/e-track-4/26.csv\n",
      "./road_tracks/e-track-4/9.csv\n",
      "./road_tracks/e-track-4/10.csv\n",
      "./road_tracks/e-track-4/16.csv\n",
      "./road_tracks/e-track-4/8.csv\n",
      "./road_tracks/e-track-4/5.csv\n",
      "./road_tracks/e-track-4/21.csv\n",
      "./road_tracks/e-track-4/3.csv\n",
      "./road_tracks/e-track-4/25.csv\n",
      "./road_tracks/e-track-4/23.csv\n",
      "./road_tracks/e-track-4/20.csv\n",
      "./road_tracks/e-track-4/13.csv\n",
      "./road_tracks/e-track-4/28.csv\n",
      "./road_tracks/e-track-4/30.csv\n",
      "./road_tracks/e-track-4/1.csv\n",
      "./road_tracks/e-track-4/18.csv\n",
      "./road_tracks/e-track-4/6.csv\n",
      "./road_tracks/e-track-4/7.csv\n",
      "./road_tracks/e-track-4/22.csv\n",
      "./road_tracks/e-track-4/15.csv\n",
      "./road_tracks/e-track-4/2.csv\n",
      "./road_tracks/e-track-4/17.csv\n",
      "./road_tracks/e-track-4/14.csv\n",
      "./road_tracks/e-track-4/27.csv\n",
      "./road_tracks/e-track-4/12.csv\n",
      "./road_tracks/e-track-4/29.csv\n",
      "./road_tracks/e-track-5/24.csv\n",
      "./road_tracks/e-track-5/19.csv\n",
      "./road_tracks/e-track-5/11.csv\n",
      "./road_tracks/e-track-5/4.csv\n",
      "./road_tracks/e-track-5/26.csv\n",
      "./road_tracks/e-track-5/9.csv\n",
      "./road_tracks/e-track-5/10.csv\n",
      "./road_tracks/e-track-5/16.csv\n",
      "./road_tracks/e-track-5/8.csv\n",
      "./road_tracks/e-track-5/5.csv\n",
      "./road_tracks/e-track-5/21.csv\n",
      "./road_tracks/e-track-5/3.csv\n",
      "./road_tracks/e-track-5/25.csv\n",
      "./road_tracks/e-track-5/23.csv\n",
      "./road_tracks/e-track-5/20.csv\n",
      "./road_tracks/e-track-5/13.csv\n",
      "./road_tracks/e-track-5/28.csv\n",
      "./road_tracks/e-track-5/30.csv\n",
      "./road_tracks/e-track-5/1.csv\n",
      "./road_tracks/e-track-5/18.csv\n",
      "./road_tracks/e-track-5/6.csv\n",
      "./road_tracks/e-track-5/7.csv\n",
      "./road_tracks/e-track-5/22.csv\n",
      "./road_tracks/e-track-5/15.csv\n",
      "./road_tracks/e-track-5/2.csv\n",
      "./road_tracks/e-track-5/17.csv\n",
      "./road_tracks/e-track-5/14.csv\n",
      "./road_tracks/e-track-5/27.csv\n",
      "./road_tracks/e-track-5/12.csv\n",
      "./road_tracks/e-track-5/29.csv\n",
      "./road_tracks/e-track-6/24.csv\n",
      "./road_tracks/e-track-6/19.csv\n",
      "./road_tracks/e-track-6/11.csv\n",
      "./road_tracks/e-track-6/4.csv\n",
      "./road_tracks/e-track-6/26.csv\n",
      "./road_tracks/e-track-6/9.csv\n",
      "./road_tracks/e-track-6/10.csv\n",
      "./road_tracks/e-track-6/16.csv\n",
      "./road_tracks/e-track-6/8.csv\n",
      "./road_tracks/e-track-6/5.csv\n",
      "./road_tracks/e-track-6/21.csv\n",
      "./road_tracks/e-track-6/3.csv\n",
      "./road_tracks/e-track-6/25.csv\n",
      "./road_tracks/e-track-6/23.csv\n",
      "./road_tracks/e-track-6/20.csv\n",
      "./road_tracks/e-track-6/13.csv\n",
      "./road_tracks/e-track-6/28.csv\n",
      "./road_tracks/e-track-6/30.csv\n",
      "./road_tracks/e-track-6/1.csv\n",
      "./road_tracks/e-track-6/18.csv\n",
      "./road_tracks/e-track-6/6.csv\n",
      "./road_tracks/e-track-6/7.csv\n",
      "./road_tracks/e-track-6/22.csv\n",
      "./road_tracks/e-track-6/15.csv\n",
      "./road_tracks/e-track-6/2.csv\n",
      "./road_tracks/e-track-6/17.csv\n",
      "./road_tracks/e-track-6/14.csv\n",
      "./road_tracks/e-track-6/27.csv\n",
      "./road_tracks/e-track-6/12.csv\n",
      "./road_tracks/e-track-6/29.csv\n",
      "./road_tracks/forza/24.csv\n",
      "./road_tracks/forza/19.csv\n",
      "./road_tracks/forza/11.csv\n",
      "./road_tracks/forza/4.csv\n",
      "./road_tracks/forza/26.csv\n",
      "./road_tracks/forza/9.csv\n",
      "./road_tracks/forza/10.csv\n",
      "./road_tracks/forza/16.csv\n",
      "./road_tracks/forza/8.csv\n",
      "./road_tracks/forza/5.csv\n",
      "./road_tracks/forza/21.csv\n",
      "./road_tracks/forza/3.csv\n",
      "./road_tracks/forza/25.csv\n",
      "./road_tracks/forza/23.csv\n",
      "./road_tracks/forza/20.csv\n",
      "./road_tracks/forza/13.csv\n",
      "./road_tracks/forza/28.csv\n",
      "./road_tracks/forza/30.csv\n",
      "./road_tracks/forza/1.csv\n",
      "./road_tracks/forza/18.csv\n",
      "./road_tracks/forza/6.csv\n",
      "./road_tracks/forza/7.csv\n",
      "./road_tracks/forza/22.csv\n",
      "./road_tracks/forza/15.csv\n",
      "./road_tracks/forza/2.csv\n",
      "./road_tracks/forza/17.csv\n",
      "./road_tracks/forza/14.csv\n",
      "./road_tracks/forza/27.csv\n",
      "./road_tracks/forza/12.csv\n",
      "./road_tracks/forza/29.csv\n",
      "./road_tracks/ole-road-1/24.csv\n",
      "./road_tracks/ole-road-1/19.csv\n",
      "./road_tracks/ole-road-1/11.csv\n",
      "./road_tracks/ole-road-1/4.csv\n",
      "./road_tracks/ole-road-1/26.csv\n",
      "./road_tracks/ole-road-1/9.csv\n",
      "./road_tracks/ole-road-1/10.csv\n",
      "./road_tracks/ole-road-1/16.csv\n",
      "./road_tracks/ole-road-1/8.csv\n",
      "./road_tracks/ole-road-1/5.csv\n",
      "./road_tracks/ole-road-1/21.csv\n",
      "./road_tracks/ole-road-1/3.csv\n",
      "./road_tracks/ole-road-1/25.csv\n",
      "./road_tracks/ole-road-1/23.csv\n",
      "./road_tracks/ole-road-1/20.csv\n",
      "./road_tracks/ole-road-1/13.csv\n",
      "./road_tracks/ole-road-1/28.csv\n",
      "./road_tracks/ole-road-1/30.csv\n",
      "./road_tracks/ole-road-1/1.csv\n",
      "./road_tracks/ole-road-1/18.csv\n",
      "./road_tracks/ole-road-1/6.csv\n",
      "./road_tracks/ole-road-1/7.csv\n",
      "./road_tracks/ole-road-1/22.csv\n",
      "./road_tracks/ole-road-1/15.csv\n",
      "./road_tracks/ole-road-1/2.csv\n",
      "./road_tracks/ole-road-1/17.csv\n",
      "./road_tracks/ole-road-1/14.csv\n",
      "./road_tracks/ole-road-1/27.csv\n",
      "./road_tracks/ole-road-1/12.csv\n",
      "./road_tracks/ole-road-1/29.csv\n",
      "./road_tracks/ruudskogen/24.csv\n",
      "./road_tracks/ruudskogen/19.csv\n",
      "./road_tracks/ruudskogen/11.csv\n",
      "./road_tracks/ruudskogen/4.csv\n",
      "./road_tracks/ruudskogen/26.csv\n",
      "./road_tracks/ruudskogen/9.csv\n",
      "./road_tracks/ruudskogen/10.csv\n",
      "./road_tracks/ruudskogen/16.csv\n",
      "./road_tracks/ruudskogen/8.csv\n",
      "./road_tracks/ruudskogen/5.csv\n",
      "./road_tracks/ruudskogen/21.csv\n",
      "./road_tracks/ruudskogen/3.csv\n",
      "./road_tracks/ruudskogen/25.csv\n",
      "./road_tracks/ruudskogen/23.csv\n",
      "./road_tracks/ruudskogen/20.csv\n",
      "./road_tracks/ruudskogen/13.csv\n",
      "./road_tracks/ruudskogen/28.csv\n",
      "./road_tracks/ruudskogen/30.csv\n",
      "./road_tracks/ruudskogen/1.csv\n",
      "./road_tracks/ruudskogen/18.csv\n",
      "./road_tracks/ruudskogen/6.csv\n",
      "./road_tracks/ruudskogen/7.csv\n",
      "./road_tracks/ruudskogen/22.csv\n",
      "./road_tracks/ruudskogen/15.csv\n",
      "./road_tracks/ruudskogen/2.csv\n",
      "./road_tracks/ruudskogen/17.csv\n",
      "./road_tracks/ruudskogen/14.csv\n",
      "./road_tracks/ruudskogen/27.csv\n",
      "./road_tracks/ruudskogen/12.csv\n",
      "./road_tracks/ruudskogen/29.csv\n",
      "./road_tracks/spring/24.csv\n",
      "./road_tracks/spring/19.csv\n",
      "./road_tracks/spring/11.csv\n",
      "./road_tracks/spring/4.csv\n",
      "./road_tracks/spring/26.csv\n",
      "./road_tracks/spring/9.csv\n",
      "./road_tracks/spring/10.csv\n",
      "./road_tracks/spring/16.csv\n",
      "./road_tracks/spring/8.csv\n",
      "./road_tracks/spring/5.csv\n",
      "./road_tracks/spring/21.csv\n",
      "./road_tracks/spring/3.csv\n",
      "./road_tracks/spring/25.csv\n",
      "./road_tracks/spring/23.csv\n",
      "./road_tracks/spring/20.csv\n",
      "./road_tracks/spring/13.csv\n",
      "./road_tracks/spring/28.csv\n",
      "./road_tracks/spring/30.csv\n",
      "./road_tracks/spring/1.csv\n",
      "./road_tracks/spring/18.csv\n",
      "./road_tracks/spring/6.csv\n",
      "./road_tracks/spring/7.csv\n",
      "./road_tracks/spring/22.csv\n",
      "./road_tracks/spring/15.csv\n",
      "./road_tracks/spring/2.csv\n",
      "./road_tracks/spring/17.csv\n",
      "./road_tracks/spring/14.csv\n",
      "./road_tracks/spring/27.csv\n",
      "./road_tracks/spring/12.csv\n",
      "./road_tracks/spring/29.csv\n",
      "./road_tracks/street-1/24.csv\n",
      "./road_tracks/street-1/19.csv\n",
      "./road_tracks/street-1/11.csv\n",
      "./road_tracks/street-1/4.csv\n",
      "./road_tracks/street-1/26.csv\n",
      "./road_tracks/street-1/9.csv\n",
      "./road_tracks/street-1/10.csv\n",
      "./road_tracks/street-1/16.csv\n",
      "./road_tracks/street-1/8.csv\n",
      "./road_tracks/street-1/5.csv\n",
      "./road_tracks/street-1/21.csv\n",
      "./road_tracks/street-1/3.csv\n",
      "./road_tracks/street-1/25.csv\n",
      "./road_tracks/street-1/23.csv\n",
      "./road_tracks/street-1/20.csv\n",
      "./road_tracks/street-1/13.csv\n",
      "./road_tracks/street-1/28.csv\n",
      "./road_tracks/street-1/30.csv\n",
      "./road_tracks/street-1/1.csv\n",
      "./road_tracks/street-1/18.csv\n",
      "./road_tracks/street-1/6.csv\n",
      "./road_tracks/street-1/7.csv\n",
      "./road_tracks/street-1/22.csv\n",
      "./road_tracks/street-1/15.csv\n",
      "./road_tracks/street-1/2.csv\n",
      "./road_tracks/street-1/17.csv\n",
      "./road_tracks/street-1/14.csv\n",
      "./road_tracks/street-1/27.csv\n",
      "./road_tracks/street-1/12.csv\n",
      "./road_tracks/street-1/29.csv\n",
      "./road_tracks/wheel-1/24.csv\n",
      "./road_tracks/wheel-1/19.csv\n",
      "./road_tracks/wheel-1/11.csv\n",
      "./road_tracks/wheel-1/4.csv\n",
      "./road_tracks/wheel-1/26.csv\n",
      "./road_tracks/wheel-1/9.csv\n",
      "./road_tracks/wheel-1/10.csv\n",
      "./road_tracks/wheel-1/16.csv\n",
      "./road_tracks/wheel-1/8.csv\n",
      "./road_tracks/wheel-1/5.csv\n",
      "./road_tracks/wheel-1/21.csv\n",
      "./road_tracks/wheel-1/3.csv\n",
      "./road_tracks/wheel-1/25.csv\n",
      "./road_tracks/wheel-1/23.csv\n",
      "./road_tracks/wheel-1/20.csv\n",
      "./road_tracks/wheel-1/13.csv\n",
      "./road_tracks/wheel-1/28.csv\n",
      "./road_tracks/wheel-1/30.csv\n",
      "./road_tracks/wheel-1/1.csv\n",
      "./road_tracks/wheel-1/18.csv\n",
      "./road_tracks/wheel-1/6.csv\n",
      "./road_tracks/wheel-1/7.csv\n",
      "./road_tracks/wheel-1/22.csv\n",
      "./road_tracks/wheel-1/15.csv\n",
      "./road_tracks/wheel-1/2.csv\n",
      "./road_tracks/wheel-1/17.csv\n",
      "./road_tracks/wheel-1/14.csv\n",
      "./road_tracks/wheel-1/27.csv\n",
      "./road_tracks/wheel-1/12.csv\n",
      "./road_tracks/wheel-1/29.csv\n",
      "./road_tracks/wheel-2/24.csv\n",
      "./road_tracks/wheel-2/19.csv\n",
      "./road_tracks/wheel-2/11.csv\n",
      "./road_tracks/wheel-2/4.csv\n",
      "./road_tracks/wheel-2/26.csv\n",
      "./road_tracks/wheel-2/9.csv\n",
      "./road_tracks/wheel-2/10.csv\n",
      "./road_tracks/wheel-2/16.csv\n",
      "./road_tracks/wheel-2/8.csv\n",
      "./road_tracks/wheel-2/5.csv\n",
      "./road_tracks/wheel-2/21.csv\n",
      "./road_tracks/wheel-2/3.csv\n",
      "./road_tracks/wheel-2/25.csv\n",
      "./road_tracks/wheel-2/23.csv\n",
      "./road_tracks/wheel-2/20.csv\n",
      "./road_tracks/wheel-2/13.csv\n",
      "./road_tracks/wheel-2/28.csv\n",
      "./road_tracks/wheel-2/30.csv\n",
      "./road_tracks/wheel-2/1.csv\n",
      "./road_tracks/wheel-2/18.csv\n",
      "./road_tracks/wheel-2/6.csv\n",
      "./road_tracks/wheel-2/7.csv\n",
      "./road_tracks/wheel-2/22.csv\n",
      "./road_tracks/wheel-2/15.csv\n",
      "./road_tracks/wheel-2/2.csv\n",
      "./road_tracks/wheel-2/17.csv\n",
      "./road_tracks/wheel-2/14.csv\n",
      "./road_tracks/wheel-2/27.csv\n",
      "./road_tracks/wheel-2/12.csv\n",
      "./road_tracks/wheel-2/29.csv\n"
     ]
    }
   ],
   "source": [
    "def array():\n",
    "    return []\n",
    "mydict=defaultdict(array)\n",
    "\n",
    "file_names=['./road_tracks/aalborg','./road_tracks/alpine-1','./road_tracks/alpine-2'\n",
    "            ,'./road_tracks/brondehach','./road_tracks/corkscrew','./road_tracks/eroad','./road_tracks/e-track-3',\n",
    "            './road_tracks/e-track-4','./road_tracks/e-track-5','./road_tracks/e-track-6','./road_tracks/forza',\n",
    "            './road_tracks/ole-road-1','./road_tracks/ruudskogen','./road_tracks/spring','./road_tracks/street-1',\n",
    "           './road_tracks/wheel-1','./road_tracks/wheel-2']\n",
    "for i in file_names:\n",
    "    names=[]\n",
    "    for file in os.listdir(i):\n",
    "        if file.endswith(\".csv\"):\n",
    "            #print(os.path.join(\"./\", file))\n",
    "            names.append(os.path.join(i, file))\n",
    "            print os.path.join(i, file)\n",
    "    mydict[i]=names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./road_tracks/brondehach\n",
      "./road_tracks/ruudskogen\n",
      "./road_tracks/street-1\n",
      "./road_tracks/forza\n",
      "./road_tracks/aalborg\n",
      "./road_tracks/e-track-5\n",
      "./road_tracks/spring\n",
      "./road_tracks/eroad\n",
      "./road_tracks/alpine-1\n",
      "./road_tracks/ole-road-1\n",
      "./road_tracks/wheel-2\n",
      "./road_tracks/alpine-2\n",
      "./road_tracks/wheel-1\n",
      "./road_tracks/e-track-3\n",
      "./road_tracks/e-track-4\n",
      "./road_tracks/corkscrew\n",
      "./road_tracks/e-track-6\n"
     ]
    }
   ],
   "source": [
    "Xtrain=np.zeros(73)\n",
    "ytrain=np.zeros(4)\n",
    "Xval=np.zeros(73)\n",
    "yval=np.zeros(4)    \n",
    "keys=mydict.keys()\n",
    "for k in keys:\n",
    "    print k\n",
    "    names=mydict[k]\n",
    "    j=1\n",
    "    for i in names:\n",
    "        data=pd.read_csv(i)\n",
    "        #print data.columns\n",
    "        #print len(data.columns)\n",
    "        del data[' CurrentLapTime']\n",
    "        data=data.dropna()\n",
    "        data=data.values\n",
    "        if j<=28:\n",
    "            Xtrain=np.vstack((Xtrain,data[:,:73]))\n",
    "            ytrain=np.vstack((ytrain,data[:,[-5,-4,-3,-1]]))\n",
    "        else:\n",
    "            Xval=np.vstack((Xval,data[:,:73]))\n",
    "            yval=np.vstack((yval,data[:,[-5,-4,-3,-1]]))\n",
    "        j+=1\n",
    "        #print Xtrain.shape\n",
    "        #print ytrain.shape\n",
    "Xtrain=Xtrain[1:]\n",
    "ytrain=ytrain[1:]\n",
    "Xval=Xval[1:]\n",
    "yval=yval[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print Xtrain.shape\n",
    "print Xval.shape\n",
    "names=[]\n",
    "for file in os.listdir(\"./c-speedway\"):\n",
    "    if file.endswith(\".csv\"):\n",
    "        #print(os.path.join(\"./\", file))\n",
    "        names.append(os.path.join(\"./c-speedway\", file))\n",
    "j=1\n",
    "for i in names:\n",
    "    data=pd.read_csv(i)\n",
    "    print i\n",
    "    #print data.columns\n",
    "    #print len(data.columns)\n",
    "    del data[' CurrentLapTime']\n",
    "    data=data.values\n",
    "    if j<=28:\n",
    "        Xtrain=np.vstack((Xtrain,data[:,:73]))\n",
    "        ytrain=np.vstack((ytrain,data[:,[-5,-4,-3,-1]]))\n",
    "    else:\n",
    "        Xval=np.vstack((Xval,data[:,:73]))\n",
    "        yval=np.vstack((yval,data[:,[-5,-4,-3,-1]]))\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7914420, 73)\n",
      "(7914420, 4)\n",
      "(570030, 73)\n",
      "(570030, 4)\n"
     ]
    }
   ],
   "source": [
    "print Xtrain.shape\n",
    "print ytrain.shape\n",
    "print Xval.shape\n",
    "print yval.shape\n",
    "#print np.argwhere(ytrain[:,1]==np.nan)\n",
    "#print np.argwhere(yval[:,1]==np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#SS=StandardScaler()\n",
    "Xtrain=SS.fit_transform(Xtrain)\n",
    "#print SS.mean_\n",
    "Xval=Xval-SS.mean_\n",
    "Xval=Xval/SS.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean1=np.mean(Xtrain,axis=0)\n",
    "std1=np.std(Xtrain,axis=0)\n",
    "Xtrain-=mean1\n",
    "Xtrain/=std1\n",
    "Xval-=mean1\n",
    "Xval/=std1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.7937995    4.02199604   3.9631125    4.91414343   0.96945284\n",
      "   2.18230971   3.22777605   0.48280224   0.30721757   0.24259211\n",
      "   0.19365049   0.16144993   0.14010995   0.11945007   0.10334269\n",
      "   0.09632415   0.09678248   0.0989198    0.10488009   0.11513269\n",
      "   0.13333954   0.16010394   0.18992601   0.23426159   0.39235986\n",
      "   0.40859869   0.27504722   0.20611495   0.16342354   0.1349647\n",
      "   0.12093616   0.11192235   0.10532554   0.10678793   0.1103372\n",
      "   0.11781511   0.13082231   0.14989912   0.17441721   0.21274631\n",
      "   0.2775179    0.37374183   0.50893578   1.44109464   1.83244622\n",
      "   2.24343975  28.75932643   4.7528484   45.45930484  44.23065677\n",
      "  38.58314484  27.73921814  12.66547123  10.3969761    7.54173105\n",
      "   3.46387738   2.06775165   2.06723142   2.10520004   3.26358741\n",
      "   5.33269245   9.79282728  12.84047622  26.21779515  37.64945246\n",
      "  44.68971738  45.24194509   7.48834856   2.27606801   2.24800208\n",
      "   2.25417145   2.22356638  73.70914523]\n",
      "[  1.08073734e+01   4.60639069e+00   3.96313432e+00   4.92240924e+00\n",
      "   9.69452843e-01   2.18230971e+00   3.91197976e+00   4.82802241e-01\n",
      "   3.07217568e-01   2.42592108e-01   1.93650487e-01   1.61449930e-01\n",
      "   1.40109955e-01   1.19450070e-01   1.03342693e-01   9.63241537e-02\n",
      "   9.67824793e-02   9.89197976e-02   1.04880093e-01   1.15132689e-01\n",
      "   1.33339540e-01   1.60103935e-01   1.89926010e-01   2.34261585e-01\n",
      "   3.92359862e-01   4.08598687e-01   2.75047223e-01   2.06114949e-01\n",
      "   1.63423537e-01   1.34964703e-01   1.20936158e-01   1.11922350e-01\n",
      "   1.05325541e-01   1.06787931e-01   1.10337198e-01   1.17815115e-01\n",
      "   1.30822309e-01   1.49899116e-01   1.74417208e-01   2.12746307e-01\n",
      "   2.77517897e-01   3.73741825e-01   5.08935784e-01   1.44109464e+00\n",
      "   1.83244622e+00   2.35663672e+00   2.99299063e+01   4.79317724e+00\n",
      "   4.54593048e+01   4.42306568e+01   3.85831448e+01   2.77392181e+01\n",
      "   1.26654712e+01   1.03969761e+01   7.54173105e+00   3.46387738e+00\n",
      "   2.06775165e+00   2.06723142e+00   2.10520004e+00   3.26358741e+00\n",
      "   5.33269245e+00   9.79282728e+00   1.28404762e+01   2.62177952e+01\n",
      "   3.76494525e+01   4.46897174e+01   4.52419451e+01   1.00623278e+01\n",
      "   2.39005610e+00   2.36875645e+00   2.36111183e+00   2.33811675e+00\n",
      "   1.05510479e+02]\n",
      "[ -1.35738571e-02  -5.84394644e-01  -2.18228134e-05  -8.26580744e-03\n",
      "   0.00000000e+00   0.00000000e+00  -6.84203711e-01   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00  -1.13196971e-01  -1.17057990e+00  -4.03288346e-02\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00  -2.57397927e+00\n",
      "  -1.13988089e-01  -1.20754367e-01  -1.06940384e-01  -1.14550367e-01\n",
      "  -3.18013333e+01]\n"
     ]
    }
   ],
   "source": [
    "print np.max(Xval,axis=0)\n",
    "print np.max(Xtrain,axis=0)\n",
    "print np.max(Xval,axis=0)-np.max(Xtrain,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 1024)              75776     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 775,836\n",
      "Trainable params: 775,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1024,input_shape=[73],activation='relu',\n",
    "                kernel_initializer='lecun_normal'))\n",
    "model.add(Dense(512,activation='relu',kernel_initializer='lecun_normal'))\n",
    "model.add(Dense(256,activation='relu',kernel_initializer='lecun_normal'))\n",
    "model.add(Dense(128,activation='relu',kernel_initializer='lecun_normal'))\n",
    "model.add(Dense(64,activation='relu',kernel_initializer='lecun_normal'))\n",
    "model.add(Dense(32,activation='relu',kernel_initializer='lecun_normal'))\n",
    "model.add(Dense(16,activation='relu',kernel_initializer='lecun_normal'))\n",
    "model.add(Dense(8,activation='relu',kernel_initializer='lecun_normal'))\n",
    "model.add(Dense(4,kernel_initializer='lecun_normal'))\n",
    "adam=Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model.summary()\n",
    "model.compile(loss='mean_squared_error',               \n",
    "          optimizer=adam,\n",
    "          metrics=['mean_absolute_error']\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7914420 samples, validate on 570030 samples\n",
      "Epoch 1/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0104 - mean_absolute_error: 0.0409Epoch 00001: val_loss improved from inf to 0.00632, saving model to weights-improvement-01-0.0104.hdf5\n",
      "7914420/7914420 [==============================] - 417s 53us/step - loss: 0.0104 - mean_absolute_error: 0.0409 - val_loss: 0.0063 - val_mean_absolute_error: 0.0284\n",
      "Epoch 2/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0052 - mean_absolute_error: 0.0254Epoch 00002: val_loss improved from 0.00632 to 0.00514, saving model to weights-improvement-02-0.0052.hdf5\n",
      "7914420/7914420 [==============================] - 414s 52us/step - loss: 0.0052 - mean_absolute_error: 0.0254 - val_loss: 0.0051 - val_mean_absolute_error: 0.0244\n",
      "Epoch 3/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0044 - mean_absolute_error: 0.0224Epoch 00003: val_loss improved from 0.00514 to 0.00448, saving model to weights-improvement-03-0.0044.hdf5\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0044 - mean_absolute_error: 0.0224 - val_loss: 0.0045 - val_mean_absolute_error: 0.0207\n",
      "Epoch 4/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0039 - mean_absolute_error: 0.0205Epoch 00004: val_loss improved from 0.00448 to 0.00425, saving model to weights-improvement-04-0.0039.hdf5\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0039 - mean_absolute_error: 0.0205 - val_loss: 0.0042 - val_mean_absolute_error: 0.0205\n",
      "Epoch 5/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0036 - mean_absolute_error: 0.0193Epoch 00005: val_loss improved from 0.00425 to 0.00419, saving model to weights-improvement-05-0.0036.hdf5\n",
      "7914420/7914420 [==============================] - 414s 52us/step - loss: 0.0036 - mean_absolute_error: 0.0193 - val_loss: 0.0042 - val_mean_absolute_error: 0.0202\n",
      "Epoch 6/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0034 - mean_absolute_error: 0.0185Epoch 00006: val_loss improved from 0.00419 to 0.00383, saving model to weights-improvement-06-0.0034.hdf5\n",
      "7914420/7914420 [==============================] - 414s 52us/step - loss: 0.0034 - mean_absolute_error: 0.0185 - val_loss: 0.0038 - val_mean_absolute_error: 0.0191\n",
      "Epoch 7/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0177Epoch 00007: val_loss improved from 0.00383 to 0.00370, saving model to weights-improvement-07-0.0032.hdf5\n",
      "7914420/7914420 [==============================] - 414s 52us/step - loss: 0.0032 - mean_absolute_error: 0.0177 - val_loss: 0.0037 - val_mean_absolute_error: 0.0181\n",
      "Epoch 8/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0030 - mean_absolute_error: 0.0171Epoch 00008: val_loss improved from 0.00370 to 0.00357, saving model to weights-improvement-08-0.0030.hdf5\n",
      "7914420/7914420 [==============================] - 415s 52us/step - loss: 0.0030 - mean_absolute_error: 0.0171 - val_loss: 0.0036 - val_mean_absolute_error: 0.0171\n",
      "Epoch 9/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0029 - mean_absolute_error: 0.0166Epoch 00009: val_loss improved from 0.00357 to 0.00349, saving model to weights-improvement-09-0.0029.hdf5\n",
      "7914420/7914420 [==============================] - 414s 52us/step - loss: 0.0029 - mean_absolute_error: 0.0166 - val_loss: 0.0035 - val_mean_absolute_error: 0.0170\n",
      "Epoch 10/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0027 - mean_absolute_error: 0.0162Epoch 00010: val_loss improved from 0.00349 to 0.00331, saving model to weights-improvement-10-0.0027.hdf5\n",
      "7914420/7914420 [==============================] - 415s 52us/step - loss: 0.0027 - mean_absolute_error: 0.0162 - val_loss: 0.0033 - val_mean_absolute_error: 0.0173\n",
      "Epoch 11/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0158Epoch 00011: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 414s 52us/step - loss: 0.0026 - mean_absolute_error: 0.0158 - val_loss: 0.0033 - val_mean_absolute_error: 0.0163\n",
      "Epoch 12/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0154Epoch 00012: val_loss improved from 0.00331 to 0.00324, saving model to weights-improvement-12-0.0026.hdf5\n",
      "7914420/7914420 [==============================] - 415s 52us/step - loss: 0.0026 - mean_absolute_error: 0.0154 - val_loss: 0.0032 - val_mean_absolute_error: 0.0159\n",
      "Epoch 13/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0151Epoch 00013: val_loss improved from 0.00324 to 0.00321, saving model to weights-improvement-13-0.0025.hdf5\n",
      "7914420/7914420 [==============================] - 414s 52us/step - loss: 0.0025 - mean_absolute_error: 0.0151 - val_loss: 0.0032 - val_mean_absolute_error: 0.0161\n",
      "Epoch 14/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0024 - mean_absolute_error: 0.0149Epoch 00014: val_loss improved from 0.00321 to 0.00318, saving model to weights-improvement-14-0.0024.hdf5\n",
      "7914420/7914420 [==============================] - 415s 52us/step - loss: 0.0024 - mean_absolute_error: 0.0149 - val_loss: 0.0032 - val_mean_absolute_error: 0.0165\n",
      "Epoch 15/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0146Epoch 00015: val_loss improved from 0.00318 to 0.00312, saving model to weights-improvement-15-0.0023.hdf5\n",
      "7914420/7914420 [==============================] - 415s 52us/step - loss: 0.0023 - mean_absolute_error: 0.0146 - val_loss: 0.0031 - val_mean_absolute_error: 0.0158\n",
      "Epoch 16/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0023 - mean_absolute_error: 0.0144Epoch 00016: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 415s 52us/step - loss: 0.0023 - mean_absolute_error: 0.0144 - val_loss: 0.0032 - val_mean_absolute_error: 0.0170\n",
      "Epoch 17/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0142Epoch 00017: val_loss improved from 0.00312 to 0.00307, saving model to weights-improvement-17-0.0022.hdf5\n",
      "7914420/7914420 [==============================] - 416s 53us/step - loss: 0.0022 - mean_absolute_error: 0.0142 - val_loss: 0.0031 - val_mean_absolute_error: 0.0148\n",
      "Epoch 18/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0022 - mean_absolute_error: 0.0140Epoch 00018: val_loss improved from 0.00307 to 0.00301, saving model to weights-improvement-18-0.0022.hdf5\n",
      "7914420/7914420 [==============================] - 415s 52us/step - loss: 0.0022 - mean_absolute_error: 0.0140 - val_loss: 0.0030 - val_mean_absolute_error: 0.0148\n",
      "Epoch 19/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0138Epoch 00019: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 415s 52us/step - loss: 0.0021 - mean_absolute_error: 0.0138 - val_loss: 0.0030 - val_mean_absolute_error: 0.0153\n",
      "Epoch 20/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0021 - mean_absolute_error: 0.0136Epoch 00020: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 415s 52us/step - loss: 0.0021 - mean_absolute_error: 0.0136 - val_loss: 0.0030 - val_mean_absolute_error: 0.0148\n",
      "Epoch 21/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0134Epoch 00021: val_loss improved from 0.00301 to 0.00296, saving model to weights-improvement-21-0.0020.hdf5\n",
      "7914420/7914420 [==============================] - 416s 53us/step - loss: 0.0020 - mean_absolute_error: 0.0134 - val_loss: 0.0030 - val_mean_absolute_error: 0.0145\n",
      "Epoch 22/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0132Epoch 00022: val_loss improved from 0.00296 to 0.00293, saving model to weights-improvement-22-0.0020.hdf5\n",
      "7914420/7914420 [==============================] - 414s 52us/step - loss: 0.0020 - mean_absolute_error: 0.0132 - val_loss: 0.0029 - val_mean_absolute_error: 0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0020 - mean_absolute_error: 0.0131Epoch 00023: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0020 - mean_absolute_error: 0.0131 - val_loss: 0.0030 - val_mean_absolute_error: 0.0147\n",
      "Epoch 24/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0129Epoch 00024: val_loss improved from 0.00293 to 0.00289, saving model to weights-improvement-24-0.0019.hdf5\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0019 - mean_absolute_error: 0.0129 - val_loss: 0.0029 - val_mean_absolute_error: 0.0141\n",
      "Epoch 25/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0128Epoch 00025: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0019 - mean_absolute_error: 0.0128 - val_loss: 0.0029 - val_mean_absolute_error: 0.0139\n",
      "Epoch 26/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0126Epoch 00026: val_loss improved from 0.00289 to 0.00285, saving model to weights-improvement-26-0.0019.hdf5\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0019 - mean_absolute_error: 0.0126 - val_loss: 0.0028 - val_mean_absolute_error: 0.0145\n",
      "Epoch 27/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0125Epoch 00027: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0018 - mean_absolute_error: 0.0125 - val_loss: 0.0029 - val_mean_absolute_error: 0.0142\n",
      "Epoch 28/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0124Epoch 00028: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0018 - mean_absolute_error: 0.0124 - val_loss: 0.0029 - val_mean_absolute_error: 0.0138\n",
      "Epoch 29/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0122Epoch 00029: val_loss improved from 0.00285 to 0.00283, saving model to weights-improvement-29-0.0018.hdf5\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0018 - mean_absolute_error: 0.0122 - val_loss: 0.0028 - val_mean_absolute_error: 0.0136\n",
      "Epoch 30/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0121Epoch 00030: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0018 - mean_absolute_error: 0.0121 - val_loss: 0.0028 - val_mean_absolute_error: 0.0143\n",
      "Epoch 31/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0120Epoch 00031: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0017 - mean_absolute_error: 0.0120 - val_loss: 0.0029 - val_mean_absolute_error: 0.0136\n",
      "Epoch 32/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0120Epoch 00032: val_loss improved from 0.00283 to 0.00282, saving model to weights-improvement-32-0.0017.hdf5\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0017 - mean_absolute_error: 0.0120 - val_loss: 0.0028 - val_mean_absolute_error: 0.0139\n",
      "Epoch 33/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0119Epoch 00033: val_loss improved from 0.00282 to 0.00278, saving model to weights-improvement-33-0.0017.hdf5\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0017 - mean_absolute_error: 0.0119 - val_loss: 0.0028 - val_mean_absolute_error: 0.0133\n",
      "Epoch 34/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0118Epoch 00034: val_loss improved from 0.00278 to 0.00277, saving model to weights-improvement-34-0.0017.hdf5\n",
      "7914420/7914420 [==============================] - 414s 52us/step - loss: 0.0017 - mean_absolute_error: 0.0118 - val_loss: 0.0028 - val_mean_absolute_error: 0.0130\n",
      "Epoch 35/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0117Epoch 00035: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0017 - mean_absolute_error: 0.0117 - val_loss: 0.0028 - val_mean_absolute_error: 0.0133\n",
      "Epoch 36/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0116Epoch 00036: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0016 - mean_absolute_error: 0.0116 - val_loss: 0.0028 - val_mean_absolute_error: 0.0137\n",
      "Epoch 37/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0115Epoch 00037: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0016 - mean_absolute_error: 0.0115 - val_loss: 0.0028 - val_mean_absolute_error: 0.0137\n",
      "Epoch 38/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0115Epoch 00038: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0016 - mean_absolute_error: 0.0115 - val_loss: 0.0028 - val_mean_absolute_error: 0.0133\n",
      "Epoch 39/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0114Epoch 00039: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0016 - mean_absolute_error: 0.0114 - val_loss: 0.0028 - val_mean_absolute_error: 0.0132\n",
      "Epoch 40/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0113Epoch 00040: val_loss improved from 0.00277 to 0.00274, saving model to weights-improvement-40-0.0016.hdf5\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0016 - mean_absolute_error: 0.0113 - val_loss: 0.0027 - val_mean_absolute_error: 0.0131\n",
      "Epoch 41/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0113Epoch 00041: val_loss improved from 0.00274 to 0.00266, saving model to weights-improvement-41-0.0016.hdf5\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0016 - mean_absolute_error: 0.0113 - val_loss: 0.0027 - val_mean_absolute_error: 0.0132\n",
      "Epoch 42/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0112Epoch 00042: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0015 - mean_absolute_error: 0.0112 - val_loss: 0.0027 - val_mean_absolute_error: 0.0125\n",
      "Epoch 43/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0112Epoch 00043: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0015 - mean_absolute_error: 0.0112 - val_loss: 0.0028 - val_mean_absolute_error: 0.0136\n",
      "Epoch 44/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0111Epoch 00044: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0015 - mean_absolute_error: 0.0111 - val_loss: 0.0027 - val_mean_absolute_error: 0.0123\n",
      "Epoch 45/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0111Epoch 00045: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0015 - mean_absolute_error: 0.0111 - val_loss: 0.0028 - val_mean_absolute_error: 0.0135\n",
      "Epoch 46/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0110Epoch 00046: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0015 - mean_absolute_error: 0.0110 - val_loss: 0.0027 - val_mean_absolute_error: 0.0129\n",
      "Epoch 47/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0110Epoch 00047: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0015 - mean_absolute_error: 0.0110 - val_loss: 0.0027 - val_mean_absolute_error: 0.0129\n",
      "Epoch 48/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0109Epoch 00048: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0015 - mean_absolute_error: 0.0109 - val_loss: 0.0027 - val_mean_absolute_error: 0.0132\n",
      "Epoch 49/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0109Epoch 00049: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0015 - mean_absolute_error: 0.0109 - val_loss: 0.0028 - val_mean_absolute_error: 0.0129\n",
      "Epoch 50/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0108Epoch 00050: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0014 - mean_absolute_error: 0.0108 - val_loss: 0.0027 - val_mean_absolute_error: 0.0125\n",
      "Epoch 51/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0108Epoch 00051: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0014 - mean_absolute_error: 0.0108 - val_loss: 0.0028 - val_mean_absolute_error: 0.0129\n",
      "Epoch 52/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0108Epoch 00052: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0014 - mean_absolute_error: 0.0108 - val_loss: 0.0028 - val_mean_absolute_error: 0.0126\n",
      "Epoch 53/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0107Epoch 00053: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0014 - mean_absolute_error: 0.0107 - val_loss: 0.0027 - val_mean_absolute_error: 0.0122\n",
      "Epoch 54/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0107Epoch 00054: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0014 - mean_absolute_error: 0.0107 - val_loss: 0.0027 - val_mean_absolute_error: 0.0130\n",
      "Epoch 55/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0106Epoch 00055: val_loss improved from 0.00266 to 0.00264, saving model to weights-improvement-55-0.0014.hdf5\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0014 - mean_absolute_error: 0.0106 - val_loss: 0.0026 - val_mean_absolute_error: 0.0117\n",
      "Epoch 56/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0106Epoch 00056: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0014 - mean_absolute_error: 0.0106 - val_loss: 0.0028 - val_mean_absolute_error: 0.0136\n",
      "Epoch 57/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0106Epoch 00057: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0014 - mean_absolute_error: 0.0106 - val_loss: 0.0026 - val_mean_absolute_error: 0.0123\n",
      "Epoch 58/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0105Epoch 00058: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0014 - mean_absolute_error: 0.0105 - val_loss: 0.0027 - val_mean_absolute_error: 0.0119\n",
      "Epoch 59/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0105Epoch 00059: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0014 - mean_absolute_error: 0.0105 - val_loss: 0.0027 - val_mean_absolute_error: 0.0123\n",
      "Epoch 60/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0105Epoch 00060: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0013 - mean_absolute_error: 0.0105 - val_loss: 0.0027 - val_mean_absolute_error: 0.0133\n",
      "Epoch 61/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0104Epoch 00061: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0013 - mean_absolute_error: 0.0104 - val_loss: 0.0027 - val_mean_absolute_error: 0.0120\n",
      "Epoch 62/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0104Epoch 00062: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0013 - mean_absolute_error: 0.0104 - val_loss: 0.0028 - val_mean_absolute_error: 0.0132\n",
      "Epoch 63/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0104Epoch 00063: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0013 - mean_absolute_error: 0.0104 - val_loss: 0.0026 - val_mean_absolute_error: 0.0123\n",
      "Epoch 64/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0103Epoch 00064: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0013 - mean_absolute_error: 0.0103 - val_loss: 0.0027 - val_mean_absolute_error: 0.0124\n",
      "Epoch 65/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0103Epoch 00065: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0013 - mean_absolute_error: 0.0103 - val_loss: 0.0027 - val_mean_absolute_error: 0.0129\n",
      "Epoch 66/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0103Epoch 00066: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0013 - mean_absolute_error: 0.0103 - val_loss: 0.0026 - val_mean_absolute_error: 0.0124\n",
      "Epoch 67/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0103Epoch 00067: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0013 - mean_absolute_error: 0.0103 - val_loss: 0.0026 - val_mean_absolute_error: 0.0122\n",
      "Epoch 68/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0102Epoch 00068: val_loss improved from 0.00264 to 0.00258, saving model to weights-improvement-68-0.0013.hdf5\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0013 - mean_absolute_error: 0.0102 - val_loss: 0.0026 - val_mean_absolute_error: 0.0126\n",
      "Epoch 69/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0102Epoch 00069: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0013 - mean_absolute_error: 0.0102 - val_loss: 0.0026 - val_mean_absolute_error: 0.0120\n",
      "Epoch 70/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0102Epoch 00070: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0013 - mean_absolute_error: 0.0102 - val_loss: 0.0026 - val_mean_absolute_error: 0.0118\n",
      "Epoch 71/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0101Epoch 00071: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 413s 52us/step - loss: 0.0013 - mean_absolute_error: 0.0101 - val_loss: 0.0026 - val_mean_absolute_error: 0.0119\n",
      "Epoch 72/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0013 - mean_absolute_error: 0.0102Epoch 00072: val_loss improved from 0.00258 to 0.00256, saving model to weights-improvement-72-0.0013.hdf5\n",
      "7914420/7914420 [==============================] - 414s 52us/step - loss: 0.0013 - mean_absolute_error: 0.0102 - val_loss: 0.0026 - val_mean_absolute_error: 0.0120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0101Epoch 00073: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0012 - mean_absolute_error: 0.0101 - val_loss: 0.0026 - val_mean_absolute_error: 0.0121\n",
      "Epoch 74/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0101Epoch 00074: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0012 - mean_absolute_error: 0.0101 - val_loss: 0.0026 - val_mean_absolute_error: 0.0122\n",
      "Epoch 75/75\n",
      "7913472/7914420 [============================>.] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0101Epoch 00075: val_loss did not improve\n",
      "7914420/7914420 [==============================] - 412s 52us/step - loss: 0.0012 - mean_absolute_error: 0.0101 - val_loss: 0.0026 - val_mean_absolute_error: 0.0120\n"
     ]
    }
   ],
   "source": [
    "res = model.fit(Xtrain,ytrain,batch_size=2048, epochs=75, validation_data=(Xval,yval),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe423957150>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAD8CAYAAACsNgQYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGOMMYny/wEVRiePrHhwjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe42d6dea50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(75)\n",
    "    # plt.plot(x, res.history['acc'], label='train')\n",
    "    # plt.plot(x, res.history['val_acc'], label='val')\n",
    "    # plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    # plt.show()\n",
    "\n",
    "plt.plot(x, res.history['loss'], label='train')\n",
    "plt.plot(x, res.history['val_loss'], label='val')\n",
    "plt.plot(x,res.history['mean_absolute_error'],label='mean_absolute_error')\n",
    "plt.plot(x,res.history['val_mean_absolute_error'],label='val_mean_absolute_error')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights-improvement-72-0.0013.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2)\n"
     ]
    }
   ],
   "source": [
    "weights=[]\n",
    "for layer in model.layers:\n",
    "    weights.append(layer.get_weights())\n",
    "    \n",
    "weights=np.array(weights)\n",
    "print weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1=weights[0,0]\n",
    "b1=weights[0,1]\n",
    "W2=weights[1,0]\n",
    "b2=weights[1,1]\n",
    "W3=weights[2,0]\n",
    "b3=weights[2,1]\n",
    "W4=weights[3,0]\n",
    "b4=weights[3,1]\n",
    "W5=weights[4,0]\n",
    "b5=weights[4,1]\n",
    "W6=weights[5,0]\n",
    "b6=weights[5,1]\n",
    "W7=weights[6,0]\n",
    "b7=weights[6,1]\n",
    "W8=weights[7,0]\n",
    "b8=weights[7,1]\n",
    "W9=weights[8,0]\n",
    "b9=weights[8,1]\n",
    "np.savetxt('W1',W1)\n",
    "np.savetxt('W2',W2)\n",
    "np.savetxt('W3',W3)\n",
    "np.savetxt('W4',W4)\n",
    "np.savetxt('W5',W5)\n",
    "np.savetxt('W6',W6)\n",
    "np.savetxt('W7',W7)\n",
    "np.savetxt('W8',W8)\n",
    "np.savetxt('W9',W9)\n",
    "\n",
    "np.savetxt('b1',b1)\n",
    "np.savetxt('b2',b2)\n",
    "np.savetxt('b3',b3)\n",
    "np.savetxt('b4',b4)\n",
    "np.savetxt('b5',b5)\n",
    "np.savetxt('b6',b6)\n",
    "np.savetxt('b7',b7)\n",
    "np.savetxt('b8',b8)\n",
    "np.savetxt('b9',b9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('mean1',mean1)\n",
    "np.savetxt('std1',std1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73,)\n"
     ]
    }
   ],
   "source": [
    "print Xval[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9766302   0.00383111  0.64559564  0.02544233]\n"
     ]
    }
   ],
   "source": [
    "out1=np.dot(Xval[100],W1)+b1\n",
    "out1[out1<0]=0.0\n",
    "out2=np.dot(out1,W2)+b2\n",
    "out2[out2<0]=0.0\n",
    "out3=np.dot(out2,W3)+b3\n",
    "out3[out3<0]=0.0\n",
    "out4=np.dot(out3,W4)+b4\n",
    "out4[out4<0]=0.0\n",
    "out5=np.dot(out4,W5)+b5\n",
    "out5[out5<0]=0.0\n",
    "out6=np.dot(out5,W6)+b6\n",
    "out6[out6<0]=0.0\n",
    "out7=np.dot(out6,W7)+b7\n",
    "out7[out7<0]=0.0\n",
    "out8=np.dot(out7,W8)+b8\n",
    "out8[out8<0]=0.0\n",
    "out9=np.dot(out8,W9)+b9\n",
    "print out9\n",
    "#print out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73,)\n",
      "[[ 0.97663021  0.00383111  0.64559567  0.02544206]]\n"
     ]
    }
   ],
   "source": [
    "print Xval[0].shape\n",
    "print model.predict(Xval[100:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
